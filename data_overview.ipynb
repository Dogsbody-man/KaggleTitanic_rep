{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe07076",
   "metadata": {},
   "source": [
    "Save train and test data as pandas DataFrame and create a combine df to make changes quicly. Let's check possible dependencies among features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dded2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('titanic/train.csv')\n",
    "test_df = pd.read_csv('titanic/test.csv')\n",
    "combine = [train_df, test_df]\n",
    "train_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e04975",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()\n",
    "print('--------------------------------')\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8ce0ba",
   "metadata": {},
   "source": [
    "From pd info we can see that:\n",
    "    1. size of train dataset is 891 out of 2224 passangers\n",
    "    2. the percentage of survived passangers in train dataset is 38% which is similar to the overall 32% survival rate\n",
    "    3. some columns do not have a values. Therefore, I need to fill in the missing ones in Ages, Embarked columns or drop(maybe Cabin)\n",
    "    4. there are 7 numerical, 2 categorical and 2 features with mixed datatype\n",
    "    5. we, difenetly, has correletions between Pclass and Survived\n",
    "    6. checking a Ticket column as the price range can be interesting. There are duplicate tickets(only 681 unique value). We need to check average/median cost of tickets(0 - min value, 512 - max value, median - 14)\n",
    "    7. three ports(most common is S - 644 times)\n",
    "    8. mens on the ship were 577 that constitudes 65%. But women show better survival(68% out of passengers that were surveved)\n",
    "    9. we should watch on average age(29 years), maybe divide into groups. Min ages is 5 months, max is 80 years\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85361c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2de14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe(include=['O'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_sex = train_df.groupby('Sex')['Survived'].mean()\n",
    "survival_sex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd1a1ee",
   "metadata": {},
   "source": [
    "Divide our features on numerical and other type of data(without including Survived and PassengerID columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff693e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_indices = [0, 1, 2, 5, 6, 7, 9]\n",
    "categorical_indices = [3, 4, 8, 10]\n",
    "numic_data = train_df[train_df.columns[numeric_indices]]\n",
    "categorivcal_data = train_df[train_df.columns[categorical_indices]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc9ad1c",
   "metadata": {},
   "source": [
    "Let's check and compare the correlations between features and Survival column. \n",
    "Begin with checking dependencies between numerical features and Survived column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35db4b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = train_df.corr(numeric_only=True)['Survived']\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5948cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_with_survived = train_df.corr(numeric_only=True)['Survived'].sort_values(ascending=False)\n",
    "corr_with_survived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aae523",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_matrix = corr_with_survived.to_frame()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pd_matrix, \n",
    "            annot=True,      # показывать числа\n",
    "            cmap='coolwarm', # синий-красный\n",
    "            center=0,        # 0 в центре\n",
    "            square=True,     # квадратные ячейки\n",
    "            fmt='.2f')       # 2 знака после запятой\n",
    "plt.title('pd_matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fd7050",
   "metadata": {},
   "source": [
    "After this actions we can conclude that Fare and Pclass have the strongest correlation. But this is not unexpected, becauese these columns mutually dependent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1604110",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Comparison of Categorical Features with Survival', fontsize=16, y=1.02)\n",
    "# Pclass and Survived\n",
    "sns.countplot(x='Pclass', hue='Survived', data=train_df, ax=axes[0])\n",
    "axes[0].set_title('Survival by class')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].legend(['Died', 'Survived'])\n",
    "\n",
    "# Embarked and Survived\n",
    "sns.countplot(x='Embarked', hue='Survived', data=train_df, ax=axes[1])\n",
    "axes[1].set_title('Survival by Embarked')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].legend(['Died', 'Survived'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9292ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train_df, col='Survived')\n",
    "g.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25863e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sns.FacetGrid(train_df, col='Survived')\n",
    "r.map(plt.hist, 'SibSp', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd14ec3",
   "metadata": {},
   "source": [
    "Now we can transform dataset, fix some columns(fill empty cells), and remove useless features. For this look at the hole features again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d016bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb61afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['PassengerId', 'Cabin'], axis=1, inplace=True)\n",
    "test_df.drop(['PassengerId', 'Cabin'], axis=1, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a50244",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] \n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 0, 'IsAlone'] = 1\n",
    "    dataset['Sex'] = dataset['Sex'].map({'male' : 0, 'female' : 1})\n",
    "    dataset['Embarked'].fillna('S', inplace=True)\n",
    "    dataset['Embarked'] = dataset['Embarked'].map({'S' : 1, 'C' : 2, 'Q' : 3})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b4df56",
   "metadata": {},
   "source": [
    "We removed Ticket column due to the fact that Pclass column can show as the same dependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d1fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['FamilySize', 'Parch', 'SibSp', 'Ticket'], axis=1, inplace=True)\n",
    "test_df.drop(['FamilySize', 'Parch', 'SibSp', 'Ticket'], axis=1, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d1bc6",
   "metadata": {},
   "source": [
    "If we look at the data in Name, we will see that all if the name row have one common thing(Mr, Ms, Miss or another)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df67338",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Name'].map(lambda x: x.split(',')[1].split('.')[0])\n",
    "    dataset.drop(['Name'], axis=1, inplace=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94839372",
   "metadata": {},
   "source": [
    "Replace all of the rows on Mr, Miss, Mrs, Master or Doctor. As a result, we will get only five different meanings of feature Name.\n",
    "But, firstly, check the propotion of Survived in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e45b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "was_array = ['Mr', 'Sir', 'Don', 'Jonkheer', 'Col', 'Major', 'Rev', 'Capt', 'Dr', 'Master', 'Miss', 'Mrs', 'Ms', 'Mme', 'Mlle', 'the Countess', 'Lady', 'Dona']\n",
    "will_array = ['Mr', 'Mr', 'Mr', 'Mr', 'Mr', 'Mr', 'Mr', 'Mr', 'Mr', 'Master', 'Miss', 'Mrs', 'Mrs', 'Mrs', 'Miss', 'Mrs', 'Mrs', 'Mrs']\n",
    "title_mapping = dict(zip(was_array, will_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee9a219",
   "metadata": {},
   "source": [
    "At the moment, I do not know how to group better by Age or by the fact of virgin or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f51def",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dataset in enumerate(combine):\n",
    "    dataset.reset_index(drop=True, inplace=True)\n",
    "    dataset['Title_clean'] = dataset['Title'].astype(str).str.strip()\n",
    "    dataset['Title_new'] = dataset['Title_clean'].replace(title_mapping)\n",
    "    dataset.drop(['Title', 'Title_clean'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby('Title_new')['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96284529",
   "metadata": {},
   "source": [
    "Replace missing values in Age mean value in Title.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b58368",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset.loc[(dataset.Age.isnull()) & (dataset.Title_new == 'Master'), 'Age']=5\n",
    "    dataset.loc[(dataset.Age.isnull()) & (dataset.Title_new == 'Miss'), 'Age']=22\n",
    "    dataset.loc[(dataset.Age.isnull()) & (dataset.Title_new == 'Mr'), 'Age']=33\n",
    "    dataset.loc[(dataset.Age.isnull()) & (dataset.Title_new == 'Mrs'), 'Age']=36\n",
    "    dataset['Fare'] = dataset['Fare'].astype(float)\n",
    "    mean_fare = dataset['Fare'].mean()\n",
    "    dataset.loc[dataset['Fare'].isnull(), 'Fare']=mean_fare\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e569f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data_train = train_df['Title_new']\n",
    "cat_data_test = test_df['Title_new']\n",
    "dummy_feature_train= pd.get_dummies(cat_data_train, drop_first=True, dtype=int)\n",
    "dummy_feature_test= pd.get_dummies(cat_data_test, drop_first=True, dtype=int)\n",
    "train_df = pd.concat([train_df, dummy_feature_train], axis=1)\n",
    "test_df = pd.concat([test_df, dummy_feature_test], axis=1)\n",
    "train_df.drop(['Title_new'], axis=1, inplace=True)\n",
    "test_df.drop(['Title_new'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Fare'] = train_df['Fare'].round(2)\n",
    "test_df['Fare'] = test_df['Fare'].round(2)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d48ca6f",
   "metadata": {},
   "source": [
    "Before using StandartScaler, I want to look at prediction and score of first weak model. And after that compare results with results after normilization of Age and Fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f20317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = train_df.copy()\n",
    "y_train = train_df['Survived']\n",
    "train_df = train_df.drop(['Survived'],  axis=1)\n",
    "x_train_scaled = scaler.fit_transform(train_df)\n",
    "x_test_scaled[:] = scaler.transform(test_df[:])\n",
    "x_train_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4085b66f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0c6f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = train_df['Survived']\n",
    "# x_train_scaled = x_train_scaled.drop(['Survived'],  axis=1)\n",
    "first_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "first_model.fit(x_train_scaled, y_train)\n",
    "pred = first_model.predict(x_train_scaled)\n",
    "accuracy = accuracy_score(y_train, pred)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
